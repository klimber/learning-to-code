{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descubra quem fez o ENEM 2016 apenas para treino\n",
    "\n",
    "Neste desafio deverá descobrir quais estudantes estão fazendo a prova apenas para treino.\n",
    "\n",
    "## Tópicos\n",
    "\n",
    "Neste desafio você aprenderá:\n",
    "\n",
    "- Python\n",
    "- Pandas\n",
    "- Sklearn\n",
    "- Regression\n",
    "- Classification\n",
    "\n",
    "## Requisitos\n",
    "\n",
    "Você precisará de python 3.6 (ou superior) e do gerenciador de pacotes pip.\n",
    "\n",
    "Para instalar os requisitos, execute o comando como no exemplo abaixo:\n",
    "\n",
    "    pip install -r requirements.txt\n",
    "\n",
    "## Detalhes\n",
    "\n",
    "O contexto do desafio gira em torno dos resultados do ENEM 2016 (disponíveis no arquivo train.csv). Este arquivo, e apenas ele, deve ser utilizado para todos os desafios. Qualquer dúvida a respeito das colunas, consulte o [Dicionário dos Microdados do Enem 2016](https://s3-us-west-1.amazonaws.com/acceleration-assets-highway/data-science/dicionario-de-dados.zip).\n",
    "\n",
    "Alguns estudantes decidem realizar prova do ENEM de forma precoce, como um teste (coluna IN_TREINEIRO). Neste desafio, você deve criar um modelo de classificação binária para inferir a mesma. Os resultados possíveis da sua resposta devem ser “0” ou “1”.\n",
    "\n",
    "Salve sua resposta em um arquivo chamado answer.csv com duas colunas: `NU_INSCRICAO` e `IN_TREINEIRO`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test.csv')\n",
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Queremos classificar a variável IN_TREINEIRO, avaliando os dados da coluna\n",
    "df_train.IN_TREINEIRO.value_counts()\n",
    "# Com isso podemos ver que os dados são altamente desbalanceados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A coluna IN_TREINEIRO ainda não existe no dataser de testes, adicionando-a\n",
    "df_test['IN_TREINEIRO'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mantendo no dataset de treino somente as colunas também presentes no dataset de testes\n",
    "df_train = df_train[df_test.columns]\n",
    "colunas = list(df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AS colunas TP_ENSINO, TP_DEPENDENCIA_ADM_ESC e Q027 possuem muitos valores faltantes e serão removidas\n",
    "colunas.remove('TP_ENSINO')\n",
    "colunas.remove('TP_DEPENDENCIA_ADM_ESC')\n",
    "colunas.remove('Q027')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As colunas TP_PRESENCA_CN, TP_PRESENCA_CH, TP_PRESENCA_LC, TP_PRESENCA_MT podem ser deduzidas pelas respectivas notas das provas\n",
    "colunas.remove('TP_PRESENCA_CN')\n",
    "colunas.remove('TP_PRESENCA_CH')\n",
    "colunas.remove('TP_PRESENCA_LC')\n",
    "colunas.remove('TP_PRESENCA_MT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A coluna CO_UF_RESIDENCIA contém a mesma informação de SG_UF_RESIDENCIA e será removida\n",
    "colunas.remove('CO_UF_RESIDENCIA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o dataset que conterá a resposta, e removendo a coluna NU_INSCRICAO dos dados de treino, uma vez que é somente o ID de cada participante\n",
    "colunas.remove('NU_INSCRICAO')\n",
    "answer = df_test[['NU_INSCRICAO']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preenchendo alguns dados faltantes\n",
    "# Notas faltantes serão 0, assumindo que os alunos não compareceram\n",
    "for coluna in colunas:\n",
    "    if coluna.startswith('NU_NOTA'):\n",
    "        df_train[coluna].fillna(0, inplace=True)\n",
    "        df_test[coluna].fillna(0, inplace=True)\n",
    "df_train['TP_STATUS_REDACAO'].fillna(4, inplace=True)\n",
    "df_test['TP_STATUS_REDACAO'].fillna(4, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As Colunas que iniciam com TP_ são categóricas, ajustando o tipo de dados\n",
    "for coluna in colunas:\n",
    "    if coluna.startswith('TP_'):\n",
    "        df_train[coluna] = df_train[coluna].astype('object')\n",
    "        df_test[coluna] = df_test[coluna].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies = pd.get_dummies(pd.concat([df_train[colunas], df_test[colunas]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando One Hot Encoding\n",
    "df_train = df_dummies.iloc[:df_train.shape[0]]\n",
    "df_test = df_dummies.iloc[df_train.shape[0]:]\n",
    "del df_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando teste e treino\n",
    "X_train = df_train.drop(columns=['IN_TREINEIRO'])\n",
    "y_train = df_train['IN_TREINEIRO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE\n",
    "smote = SMOTE(sampling_strategy='minority')\n",
    "X_smote, y_smote = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mantendo somente as colunas com correlação maior que 10\n",
    "df_smote = X_smote\n",
    "df_smote['IN_TREINEIRO'] = y_smote\n",
    "corr_abs = df_smote.corr().abs()\n",
    "colunas = list(corr_abs[corr_abs['IN_TREINEIRO'] > 0.30].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_smote_reduced = df_smote[colunas].drop(columns=['IN_TREINEIRO'])\n",
    "X_test_reduced = df_test[colunas].drop(columns=['IN_TREINEIRO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regressão Logistica\n",
    "reg = LogisticRegression()\n",
    "\n",
    "reg.fit(X_smote_reduced, y_smote)\n",
    "\n",
    "y_pred = reg.predict(X_smote_reduced)\n",
    "\n",
    "print ('mean_absolute_error:', mean_absolute_error(y_smote, y_pred))\n",
    "print ('mean_squared_error:', mean_squared_error(y_smote, y_pred))\n",
    "print ('r2_score:', r2_score(y_smote, y_pred))\n",
    "print ('reg score:', reg.score(X_smote_reduced, y_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "reg = RandomForestClassifier()\n",
    "\n",
    "reg.fit(X_smote_reduced, y_smote)\n",
    "\n",
    "y_pred = reg.predict(X_smote_reduced)\n",
    "\n",
    "print ('mean_absolute_error:', mean_absolute_error(y_smote, y_pred))\n",
    "print ('mean_squared_error:', mean_squared_error(y_smote, y_pred))\n",
    "print ('r2_score:', r2_score(y_smote, y_pred))\n",
    "print ('reg score:', reg.score(X_smote_reduced, y_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer['IN_TREINEIRO'] = reg.predict(X_test_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer.to_csv('answer.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bitenem4venv095578dbfc794d93b6f1e28ec380446a",
   "display_name": "Python 3.8.3 64-bit ('enem-4': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}