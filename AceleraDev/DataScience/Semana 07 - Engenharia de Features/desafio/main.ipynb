{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafio 6\n",
    "\n",
    "Neste desafio, vamos praticar _feature engineering_, um dos processos mais importantes e trabalhosos de ML. Utilizaremos o _data set_ [Countries of the world](https://www.kaggle.com/fernandol/countries-of-the-world), que contém dados sobre os 227 países do mundo com informações sobre tamanho da população, área, imigração e setores de produção.\n",
    "\n",
    "> Obs.: Por favor, não modifique o nome das funções de resposta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Setup_ geral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algumas configurações para o matplotlib.\n",
    "# %matplotlib inline\n",
    "\n",
    "from IPython.core.pylabtools import figsize\n",
    "\n",
    "\n",
    "figsize(12, 8)\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "countries = pd.read_csv(\"countries.csv\", decimal=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_names = [\n",
    "    \"Country\", \"Region\", \"Population\", \"Area\", \"Pop_density\", \"Coastline_ratio\",\n",
    "    \"Net_migration\", \"Infant_mortality\", \"GDP\", \"Literacy\", \"Phones_per_1000\",\n",
    "    \"Arable\", \"Crops\", \"Other\", \"Climate\", \"Birthrate\", \"Deathrate\", \"Agriculture\",\n",
    "    \"Industry\", \"Service\"\n",
    "]\n",
    "\n",
    "countries.columns = new_column_names\n",
    "\n",
    "countries.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observações\n",
    "\n",
    "Esse _data set_ ainda precisa de alguns ajustes iniciais. Primeiro, note que as variáveis numéricas estão usando vírgula como separador decimal e estão codificadas como strings. Corrija isso antes de continuar: transforme essas variáveis em numéricas adequadamente.\n",
    "\n",
    "Além disso, as variáveis `Country` e `Region` possuem espaços a mais no começo e no final da string. Você pode utilizar o método `str.strip()` para remover esses espaços."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicia sua análise a partir daqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sua análise começa aqui.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in [\"Country\", \"Region\"]:\n",
    "    countries[column] = countries[column].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 1\n",
    "\n",
    "Quais são as regiões (variável `Region`) presentes no _data set_? Retorne uma lista com as regiões únicas do _data set_ com os espaços à frente e atrás da string removidos (mas mantenha pontuação: ponto, hífen etc) e ordenadas em ordem alfabética."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1():\n",
    "    # Retorne aqui o resultado da questão 1.\n",
    "    lista = list(countries.Region.unique())\n",
    "    lista.sort()\n",
    "    return lista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 2\n",
    "\n",
    "Discretizando a variável `Pop_density` em 10 intervalos com `KBinsDiscretizer`, seguindo o encode `ordinal` e estratégia `quantile`, quantos países se encontram acima do 90º percentil? Responda como um único escalar inteiro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q2():\n",
    "    # Retorne aqui o resultado da questão 2.\n",
    "    from sklearn.preprocessing import KBinsDiscretizer\n",
    "    discretizer = KBinsDiscretizer(n_bins=10, encode='ordinal')\n",
    "    return countries[discretizer.fit_transform(countries[['Pop_density']]) == 9].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 3\n",
    "\n",
    "Se codificarmos as variáveis `Region` e `Climate` usando _one-hot encoding_, quantos novos atributos seriam criados? Responda como um único escalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q3():\n",
    "    # Retorne aqui o resultado da questão 3.\n",
    "    return countries.Region.nunique() + countries.Climate.fillna(0).nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 4\n",
    "\n",
    "Aplique o seguinte _pipeline_:\n",
    "\n",
    "1. Preencha as variáveis do tipo `int64` e `float64` com suas respectivas medianas.\n",
    "2. Padronize essas variáveis.\n",
    "\n",
    "Após aplicado o _pipeline_ descrito acima aos dados (somente nas variáveis dos tipos especificados), aplique o mesmo _pipeline_ (ou `ColumnTransformer`) ao dado abaixo. Qual o valor da variável `Arable` após o _pipeline_? Responda como um único float arredondado para três casas decimais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_country = [\n",
    "    'Test Country', 'NEAR EAST', -0.19032480757326514,\n",
    "    -0.3232636124824411, -0.04421734470810142, -0.27528113360605316,\n",
    "    0.13255850810281325, -0.8054845935643491, 1.0119784924248225,\n",
    "    0.6189182532646624, 1.0074863283776458, 0.20239896852403538,\n",
    "    -0.043678728558593366, -0.13929748680369286, 1.3163604645710438,\n",
    "    -0.3699637766938669, -0.6149300604558857, -0.854369594993175,\n",
    "    0.263445277972641, 0.5712416961268142\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q4():\n",
    "    # Retorne aqui o resultado da questão 4.\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    pipe = Pipeline(steps=[('inputer', SimpleImputer(strategy='median')), ('scaler',StandardScaler())])\n",
    "    pipe.fit(countries.select_dtypes(['int64', 'float64']))\n",
    "    return float(pipe.transform(pd.DataFrame(columns=new_column_names, data=[test_country]).select_dtypes(['int64', 'float64']))[0][new_column_names.index('Arable')-2].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 5\n",
    "\n",
    "Descubra o número de _outliers_ da variável `Net_migration` segundo o método do _boxplot_, ou seja, usando a lógica:\n",
    "\n",
    "$$x \\notin [Q1 - 1.5 \\times \\text{IQR}, Q3 + 1.5 \\times \\text{IQR}] \\Rightarrow x \\text{ é outlier}$$\n",
    "\n",
    "que se encontram no grupo inferior e no grupo superior.\n",
    "\n",
    "Você deveria remover da análise as observações consideradas _outliers_ segundo esse método? Responda como uma tupla de três elementos `(outliers_abaixo, outliers_acima, removeria?)` ((int, int, bool))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q5():\n",
    "    # Retorne aqui o resultado da questão 5.\n",
    "    lower_quantile = countries.Net_migration.quantile(0.25)\n",
    "    higher_quantile = countries.Net_migration.quantile(0.75)\n",
    "    iqr = higher_quantile - lower_quantile\n",
    "    lower_limit = lower_quantile - 1.5 * iqr\n",
    "    higher_limit = higher_quantile + 1.5 * iqr\n",
    "    outliers_acima = countries[countries.Net_migration > higher_limit].shape[0]\n",
    "    outliers_abaixo = countries[countries.Net_migration < lower_limit].shape[0]\n",
    "    return (outliers_abaixo, outliers_acima, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 6\n",
    "Para as questões 6 e 7 utilize a biblioteca `fetch_20newsgroups` de datasets de test do `sklearn`\n",
    "\n",
    "Considere carregar as seguintes categorias e o dataset `newsgroups`:\n",
    "\n",
    "```\n",
    "categories = ['sci.electronics', 'comp.graphics', 'rec.motorcycles']\n",
    "newsgroup = fetch_20newsgroups(subset=\"train\", categories=categories, shuffle=True, random_state=42)\n",
    "```\n",
    "\n",
    "\n",
    "Aplique `CountVectorizer` ao _data set_ `newsgroups` e descubra o número de vezes que a palavra _phone_ aparece no corpus. Responda como um único escalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories = ['sci.electronics', 'comp.graphics', 'rec.motorcycles']\n",
    "newsgroup = fetch_20newsgroups(subset=\"train\", categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q6():\n",
    "    # Retorne aqui o resultado da questão 6.\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    count = CountVectorizer()\n",
    "    count.fit(newsgroup.data)\n",
    "    return int(count.transform(newsgroup.data)[:, count.vocabulary_.get(\"phone\")].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 7\n",
    "\n",
    "Aplique `TfidfVectorizer` ao _data set_ `newsgroups` e descubra o TF-IDF da palavra _phone_. Responda como um único escalar arredondado para três casas decimais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q7():\n",
    "    # Retorne aqui o resultado da questão 4.\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    tfIdfVect = TfidfVectorizer()\n",
    "    tfIdfVect.fit(newsgroup.data)\n",
    "    return float(tfIdfVect.transform(newsgroup.data)[:, tfIdfVect.vocabulary_.get(\"phone\")].sum().round(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('venv': venv)",
   "language": "python",
   "name": "python38364bitvenvvenv054a563a8d85455797d3cd5fe1f2192b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}